{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from evoman.environment import Environment\n",
    "from controller1 import player_controller\n",
    "from evoman.controller import Controller\n",
    "from multiprocessing import Pool\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm_a(env, npopulation=200, gens=30, mutation_rate=0.05, dom_u=1, dom_l=-1):\n",
    "    \"\"\"\n",
    "    Runs Genetic Algorithm A with the provided environment and parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - env: Evoman Environment instance.\n",
    "    - npopulation: Population size.\n",
    "    - gens: Number of generations.\n",
    "    - mutation_rate: Mutation rate.\n",
    "    - dom_u: Upper bound for gene values.\n",
    "    - dom_l: Lower bound for gene values.\n",
    "    - elitism_count: Number of elites to preserve.\n",
    "\n",
    "    Returns:\n",
    "    - history_mean: List of mean fitness per generation.\n",
    "    - history_max: List of max fitness per generation.\n",
    "    - best_solution: Best solution found.\n",
    "    \"\"\"\n",
    "    n_hidden_neurons_1 = 10\n",
    "    n_hidden_neurons_2 = 5\n",
    "\n",
    "    n_vars = (\n",
    "        (env.get_num_sensors() + 1) * n_hidden_neurons_1 +  # Weights and biases from input -> hidden layer 1\n",
    "        (n_hidden_neurons_1 + 1) * n_hidden_neurons_2 +  # Weights and biases from hidden layer 1 -> hidden layer 2\n",
    "        (n_hidden_neurons_2 + 1) * 5  # Weights and biases from hidden layer 2 -> output layer (5 actions)\n",
    "    )\n",
    "\n",
    "    # Run the simulation and return the fitness\n",
    "    def simulate(x):\n",
    "        env.player_controller.set(x, env.get_num_sensors())\n",
    "        f, _, _, _ = env.play(pcont=x)\n",
    "        return f\n",
    "\n",
    "    # Evaluate the current population\n",
    "    def evaluate(population):\n",
    "        return np.array([simulate(individual) for individual in population])\n",
    "\n",
    "    # Tournament Selection\n",
    "    def tournament_selection(population, fitness, k=5):\n",
    "        selected = []\n",
    "        for _ in range(len(population)):\n",
    "            contenders = np.random.choice(len(population), k, replace=False)\n",
    "            winner = contenders[np.argmax(fitness[contenders])]\n",
    "            selected.append(population[winner])\n",
    "        return np.array(selected)\n",
    "\n",
    "    # Uniform Crossover\n",
    "    def crossover(parent1, parent2):\n",
    "        mask = np.random.rand(n_vars) < 0.5\n",
    "        child1 = np.where(mask, parent1, parent2)\n",
    "        child2 = np.where(mask, parent2, parent1)\n",
    "        return child1, child2\n",
    "\n",
    "    # Gaussian Mutation\n",
    "    def mutate(child):\n",
    "        for i in range(n_vars):\n",
    "            if np.random.rand() < mutation_rate:\n",
    "                child[i] += np.random.normal(0, 0.1)\n",
    "                child[i] = np.clip(child[i], dom_l, dom_u)\n",
    "        return child\n",
    "\n",
    "    # Initialize population\n",
    "    population = np.random.uniform(dom_l, dom_u, (npopulation, n_vars))\n",
    "    fitness = evaluate(population)\n",
    "\n",
    "    # Record fitness over generations\n",
    "    history_mean = []\n",
    "    history_max = []\n",
    "\n",
    "    # Genetic Algorithm Loop\n",
    "    for generation in range(1, gens + 1):\n",
    "        # Selection\n",
    "        selected = tournament_selection(population, fitness)\n",
    "\n",
    "        # Crossover\n",
    "        offspring = []\n",
    "        for i in range(0, npopulation, 2):\n",
    "            parent1, parent2 = selected[i], selected[i+1]\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            offspring.extend([child1, child2])\n",
    "        offspring = np.array(offspring)[:npopulation]\n",
    "\n",
    "        # Mutation\n",
    "        offspring = np.array([mutate(child) for child in offspring])\n",
    "\n",
    "        # Evaluation\n",
    "        offspring_fitness = evaluate(offspring)\n",
    "\n",
    "        # Replacement: Elitism (keep the best individual)\n",
    "        best_idx = np.argmax(fitness)\n",
    "        worst_idx = np.argmin(offspring_fitness)\n",
    "        if fitness[best_idx] > offspring_fitness[worst_idx]:\n",
    "            offspring[worst_idx] = population[best_idx]\n",
    "            offspring_fitness[worst_idx] = fitness[best_idx]\n",
    "\n",
    "        population, fitness = offspring, offspring_fitness\n",
    "\n",
    "        # Record statistics\n",
    "        history_mean.append(np.mean(fitness))\n",
    "        history_max.append(np.max(fitness))\n",
    "\n",
    "        # Logging\n",
    "        print(f'Generation {generation}: Best Fitness = {history_max[-1]:.4f}, Mean Fitness = {history_mean[-1]:.4f}')\n",
    "\n",
    "    # Get best solution\n",
    "    best_idx = np.argmax(fitness)\n",
    "    best_solution = population[best_idx]\n",
    "\n",
    "    np.savetxt('best_solution_a.txt', best_solution)\n",
    "\n",
    "    return history_mean, history_max, best_solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm_b(env, npopulation=200, gens=30, mutation_rate=0.05, dom_u=1, dom_l=-1, elitism_count=2, share_alpha=0.1, share_sigma=0.2):\n",
    "    \"\"\"\n",
    "    Runs Genetic Algorithm B (GA with Fitness Sharing for diversity maintenance).\n",
    "\n",
    "    Parameters:\n",
    "    - env: Evoman Environment instance.\n",
    "    - npopulation: Population size.\n",
    "    - gens: Number of generations.\n",
    "    - mutation_rate: Mutation rate.\n",
    "    - dom_u: Upper bound for gene values.\n",
    "    - dom_l: Lower bound for gene values.\n",
    "    - elitism_count: Number of elites to preserve.\n",
    "    - share_alpha: Sharing coefficient.\n",
    "    - share_sigma: Sharing radius.\n",
    "\n",
    "    Returns:\n",
    "    - history_mean: List of mean fitness per generation.\n",
    "    - history_max: List of max fitness per generation.\n",
    "    - best_solution: Best solution found.\n",
    "    \"\"\"\n",
    "\n",
    "    n_hidden_neurons_1 = 10\n",
    "    n_hidden_neurons_2 = 5\n",
    "\n",
    "    n_vars = (\n",
    "        (env.get_num_sensors() + 1) * n_hidden_neurons_1 +  # Weights and biases from input -> hidden layer 1\n",
    "        (n_hidden_neurons_1 + 1) * n_hidden_neurons_2 +  # Weights and biases from hidden layer 1 -> hidden layer 2\n",
    "        (n_hidden_neurons_2 + 1) * 5  # Weights and biases from hidden layer 2 -> output layer (5 actions)\n",
    "    )\n",
    "\n",
    "    # Run the simulation and return the fitness\n",
    "    def simulate(x):\n",
    "        # Set the player's controller with the weights 'x'\n",
    "        env.player_controller.set(x, env.get_num_sensors())\n",
    "        f, _, _, _ = env.play(pcont=x)\n",
    "        return f\n",
    "\n",
    "    # Evaluate the current population\n",
    "    def evaluate(population):\n",
    "        return np.array([simulate(individual) for individual in population])\n",
    "\n",
    "    # Tournament Selection\n",
    "    def tournament_selection(population, fitness, k=5):\n",
    "        selected = []\n",
    "        for _ in range(len(population)):\n",
    "            contenders = np.random.choice(len(population), k, replace=False)\n",
    "            winner = contenders[np.argmax(fitness[contenders])]\n",
    "            selected.append(population[winner])\n",
    "        return np.array(selected)\n",
    "\n",
    "    # Two-Point Crossover\n",
    "    def two_point_crossover(parent1, parent2):\n",
    "        point1 = np.random.randint(0, n_vars)\n",
    "        point2 = np.random.randint(point1, n_vars)\n",
    "        child1 = np.concatenate([parent1[:point1], parent2[point1:point2], parent1[point2:]])\n",
    "        child2 = np.concatenate([parent2[:point1], parent1[point1:point2], parent2[point2:]])\n",
    "        return child1, child2\n",
    "\n",
    "    # Gaussian Mutation\n",
    "    def mutate(child):\n",
    "        for i in range(n_vars):\n",
    "            if np.random.rand() < mutation_rate:\n",
    "                child[i] += np.random.normal(0, 0.1)\n",
    "                child[i] = np.clip(child[i], dom_l, dom_u)\n",
    "        return child\n",
    "\n",
    "    # Fitness Sharing\n",
    "    def fitness_sharing(population, fitness, alpha, sigma):\n",
    "        \"\"\"\n",
    "        Adjusts fitness based on similarity using fitness sharing.\n",
    "\n",
    "        Parameters:\n",
    "        - population: Current population.\n",
    "        - fitness: Original fitness values.\n",
    "        - alpha: Sharing coefficient.\n",
    "        - sigma: Sharing radius.\n",
    "\n",
    "        Returns:\n",
    "        - shared_fitness: Adjusted fitness values.\n",
    "        \"\"\"\n",
    "        shared_fitness = np.copy(fitness)\n",
    "        npop = population.shape[0]\n",
    "        for i in range(npop):\n",
    "            for j in range(npop):\n",
    "                if i != j:\n",
    "                    distance = np.linalg.norm(population[i] - population[j])\n",
    "                    if distance < sigma:\n",
    "                        shared_fitness[i] -= alpha * (1 - distance / sigma)\n",
    "        # Ensure that fitness doesn't become negative\n",
    "        shared_fitness = np.maximum(shared_fitness, 0)\n",
    "        return shared_fitness\n",
    "\n",
    "    # Initialize population\n",
    "    population = np.random.uniform(dom_l, dom_u, (npopulation, n_vars))\n",
    "    fitness = evaluate(population)\n",
    "\n",
    "    # Apply Fitness Sharing\n",
    "    fitness = fitness_sharing(population, fitness, share_alpha, share_sigma)\n",
    "\n",
    "    # Record fitness over generations\n",
    "    history_mean = []\n",
    "    history_max = []\n",
    "\n",
    "    # Genetic Algorithm Loop\n",
    "    for generation in range(1, gens + 1):\n",
    "        # Selection\n",
    "        selected = tournament_selection(population, fitness)\n",
    "\n",
    "        # Crossover\n",
    "        offspring = []\n",
    "        for i in range(0, npopulation, 2):\n",
    "            parent1, parent2 = selected[i], selected[i+1]\n",
    "            child1, child2 = two_point_crossover(parent1, parent2)\n",
    "            offspring.extend([child1, child2])\n",
    "        offspring = np.array(offspring)[:npopulation]\n",
    "\n",
    "        # Mutation\n",
    "        offspring = np.array([mutate(child) for child in offspring])\n",
    "\n",
    "        # Evaluation\n",
    "        offspring_fitness = evaluate(offspring)\n",
    "\n",
    "        # Apply Fitness Sharing\n",
    "        offspring_fitness = fitness_sharing(offspring, offspring_fitness, share_alpha, share_sigma)\n",
    "\n",
    "        # Replacement: Elitism (keep the best individual)\n",
    "        best_idx = np.argmax(fitness)\n",
    "        worst_idx = np.argmin(offspring_fitness)\n",
    "        if fitness[best_idx] > offspring_fitness[worst_idx]:\n",
    "            offspring[worst_idx] = population[best_idx]\n",
    "            offspring_fitness[worst_idx] = fitness[best_idx]\n",
    "\n",
    "        population, fitness = offspring, offspring_fitness\n",
    "\n",
    "        # Record statistics\n",
    "        history_mean.append(np.mean(fitness))\n",
    "        history_max.append(np.max(fitness))\n",
    "\n",
    "        # Logging\n",
    "        print(f'Generation {generation}: Best Fitness = {history_max[-1]:.4f}, Mean Fitness = {history_mean[-1]:.4f}')\n",
    "\n",
    "    # Get best solution\n",
    "    best_idx = np.argmax(fitness)\n",
    "    best_solution = population[best_idx]\n",
    "\n",
    "    np.savetxt(('best_solution_b.txt'), best_solution)\n",
    "\n",
    "    return history_mean, history_max, best_solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Parameters\n",
    "enemy = 6 # singular enemy to test\n",
    "num_runs = 10 # Change to 10 for full experiment\n",
    "npopulation = 200\n",
    "gens = 30 # Change to 30 for full experiment\n",
    "mutation_rate = 0.05\n",
    "dom_u, dom_l = 1, -1\n",
    "elitism_count_a = 1\n",
    "elitism_count_b = 2\n",
    "# Define the list of enemies to train against\n",
    "enemies = [1, 2, 3]  \n",
    "\n",
    "# The number of hidden neurons for the player controller\n",
    "n_hidden_neurons_1 = 10\n",
    "n_hidden_neurons_2 = 5\n",
    "\n",
    "# Initialize data storage\n",
    "results = {\n",
    "    'Algorithm': [],\n",
    "    'Enemy': [],\n",
    "    'Run': [],\n",
    "    'Generation': [],\n",
    "    'Mean Fitness': [],\n",
    "    'Max Fitness': [],\n",
    "    'Best Solution': []\n",
    "}\n",
    "\n",
    "best_solutions = {\n",
    "    'Algorithm': [],\n",
    "    'Enemy': [],\n",
    "    'Run': [],\n",
    "    'Best Solution': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this for Algorithm A results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for enemy in enemies:\n",
    "    print(f\"Training against enemy {enemy}\")\n",
    "        \n",
    "    for run in range(1, num_runs + 1):\n",
    "        print(f\"Run {run}/{num_runs}\")\n",
    "        \n",
    "        # Define experiment names for Algorithm A and B\n",
    "        experiment_name_a = f'optimization_test_a_run_{run}'\n",
    "        experiment_name_b = f'optimization_test_b_run_{run}'\n",
    "        \n",
    "        # Create directories for Algorithm A and B\n",
    "        os.makedirs(experiment_name_a, exist_ok=True)\n",
    "        os.makedirs(experiment_name_b, exist_ok=True)\n",
    "        \n",
    "        # Initialize Environment for Algorithm A\n",
    "        env_a = Environment(\n",
    "            experiment_name=experiment_name_a,\n",
    "            enemies=[enemy],\n",
    "            playermode=\"ai\",\n",
    "            player_controller=player_controller(n_hidden_neurons_1, n_hidden_neurons_2),\n",
    "            enemymode=\"ai\",\n",
    "            level=2,\n",
    "            speed=\"fastest\",\n",
    "            visuals=False\n",
    "        )\n",
    "        \n",
    "        # Run Algorithm A\n",
    "        mean_a, max_a, best_a = run_algorithm_a(\n",
    "            env=env_a,\n",
    "            npopulation=npopulation,\n",
    "            gens=gens,\n",
    "            mutation_rate=mutation_rate,\n",
    "            dom_u=dom_u,\n",
    "            dom_l=dom_l\n",
    "        )\n",
    "        \n",
    "        # Record data for Algorithm A\n",
    "        for gen in range(1, gens + 1):\n",
    "            results['Algorithm'].append('A')\n",
    "            results['Enemy'].append(enemy)\n",
    "            results['Run'].append(run)\n",
    "            results['Generation'].append(gen)\n",
    "            results['Mean Fitness'].append(mean_a[gen - 1])\n",
    "            results['Max Fitness'].append(max_a[gen - 1])\n",
    "            results['Best Solution'].append(best_a)\n",
    "        \n",
    "        best_solutions['Algorithm'].append('A')\n",
    "        best_solutions['Enemy'].append(enemy)\n",
    "        best_solutions['Run'].append(run)\n",
    "        best_solutions['Best Solution'].append(best_a)\n",
    "\n",
    "        # Initialize Environment for Algorithm B\n",
    "        env_b = Environment(\n",
    "            experiment_name=experiment_name_b,\n",
    "            enemies=[enemy],\n",
    "            playermode=\"ai\",\n",
    "            player_controller=player_controller(n_hidden_neurons_1, n_hidden_neurons_2),\n",
    "            enemymode=\"ai\",\n",
    "            level=2,\n",
    "            speed=\"fastest\",\n",
    "            visuals=False\n",
    "        )\n",
    "        \n",
    "        # Run Algorithm B\n",
    "        mean_b, max_b, best_b = run_algorithm_b(\n",
    "            env=env_b,\n",
    "            npopulation=npopulation,\n",
    "            gens=gens,\n",
    "            mutation_rate=mutation_rate,\n",
    "            dom_u=dom_u,\n",
    "            dom_l=dom_l,\n",
    "            elitism_count=elitism_count_b\n",
    "        )\n",
    "        \n",
    "        # Record data for Algorithm B\n",
    "        for gen in range(1, gens + 1):\n",
    "            results['Algorithm'].append('B')\n",
    "            results['Enemy'].append(enemy)\n",
    "            results['Run'].append(run)\n",
    "            results['Generation'].append(gen)\n",
    "            results['Mean Fitness'].append(mean_b[gen - 1])\n",
    "            results['Max Fitness'].append(max_b[gen - 1])\n",
    "            results['Best Solution'].append(best_b)\n",
    "        \n",
    "        best_solutions['Algorithm'].append('B')\n",
    "        best_solutions['Enemy'].append(enemy)\n",
    "        best_solutions['Run'].append(run)\n",
    "        best_solutions['Best Solution'].append(best_b)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('results_a.csv', index=False)\n",
    "\n",
    "best_solutions_df = pd.DataFrame(best_solutions)\n",
    "best_solutions_df.to_csv('best_solutions_a.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this for Algorithm B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for enemy in enemies:\n",
    "    print(f\"Training against enemy {enemy}\")\n",
    "        \n",
    "    for run in range(1, num_runs + 1):\n",
    "        print(f\"Run {run}/{num_runs}\")\n",
    "        \n",
    "        # Initialize Environment for Algorithm B\n",
    "        env_b = Environment(\n",
    "            experiment_name=experiment_name_b,\n",
    "            enemies=[enemy],\n",
    "            playermode=\"ai\",\n",
    "            player_controller=player_controller(n_hidden_neurons_1, n_hidden_neurons_2),\n",
    "            enemymode=\"ai\",\n",
    "            level=2,\n",
    "            speed=\"fastest\",\n",
    "            visuals=False\n",
    "        )\n",
    "        \n",
    "        # Run Algorithm B\n",
    "        mean_b, max_b, best_b = run_algorithm_b(\n",
    "            env=env_b,\n",
    "            npopulation=npopulation,\n",
    "            gens=gens,\n",
    "            mutation_rate=mutation_rate,\n",
    "            dom_u=dom_u,\n",
    "            dom_l=dom_l,\n",
    "            elitism_count=elitism_count_b\n",
    "        )\n",
    "        \n",
    "        # Record data for Algorithm B\n",
    "        for gen in range(1, gens + 1):\n",
    "            results['Algorithm'].append('B')\n",
    "            results['Enemy'].append(enemy)\n",
    "            results['Run'].append(run)\n",
    "            results['Generation'].append(gen)\n",
    "            results['Mean Fitness'].append(mean_b[gen - 1])\n",
    "            results['Max Fitness'].append(max_b[gen - 1])\n",
    "            results['Best Solution'].append(best_b)\n",
    "        \n",
    "        best_solutions['Algorithm'].append('B')\n",
    "        best_solutions['Enemy'].append(enemy)\n",
    "        best_solutions['Run'].append(run)\n",
    "        best_solutions['Best Solution'].append(best_b)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('results_b.csv', index=False)\n",
    "\n",
    "best_solutions_df = pd.DataFrame(best_solutions)\n",
    "best_solutions_df.to_csv('best_solutions_b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Algorithm, Enemy, Generation and compute mean and std\n",
    "grouped = results_df.groupby(['Algorithm', 'Enemy', 'Generation']).agg(\n",
    "    mean_fitness_mean=('Mean Fitness', 'mean'),\n",
    "    mean_fitness_std=('Mean Fitness', 'std'),\n",
    "    max_fitness_mean=('Max Fitness', 'mean'),\n",
    "    max_fitness_std=('Max Fitness', 'std')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the grouped data\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Subset data for the current enemy\n",
    "data_enemy = grouped[grouped['Enemy'] == enemy]\n",
    "\n",
    "# Plot Mean Fitness\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.lineplot(data=data_enemy, x='Generation', y='mean_fitness_mean', hue='Algorithm', marker='o')\n",
    "plt.fill_between(\n",
    "\tdata_enemy['Generation'],\n",
    "\tdata_enemy['mean_fitness_mean'] - data_enemy['mean_fitness_std'],\n",
    "\tdata_enemy['mean_fitness_mean'] + data_enemy['mean_fitness_std'],\n",
    "\talpha=0.2\n",
    ")\n",
    "plt.title(f'Enemy {enemy}: Average Mean Fitness Across Generations')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Mean Fitness')\n",
    "plt.legend(title='Algorithm')\n",
    "\n",
    "# Plot Max Fitness\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.lineplot(data=data_enemy, x='Generation', y='max_fitness_mean', hue='Algorithm', marker='o')\n",
    "plt.fill_between(\n",
    "\tdata_enemy['Generation'],\n",
    "\tdata_enemy['max_fitness_mean'] - data_enemy['max_fitness_std'],\n",
    "\tdata_enemy['max_fitness_mean'] + data_enemy['max_fitness_std'],\n",
    "\talpha=0.2\n",
    ")\n",
    "plt.title(f'Enemy {enemy}: Average Max Fitness Across Generations')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Max Fitness')\n",
    "plt.legend(title='Algorithm')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Run the best solution on 2 other enemies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enemies = [1, 6, 8]\n",
    "\n",
    "experiment_name = 'test_other_enemies'\n",
    "os.makedirs(experiment_name, exist_ok=True)\n",
    "\n",
    "# Load best solutions\n",
    "best_solutions_a = np.loadtxt('best_solution_b.txt')\n",
    "\n",
    "n_hidden1 = 10\n",
    "n_hidden2 = 5\n",
    "\n",
    "for enemy in enemies:\n",
    "\tenv = Environment(\n",
    "\t\texperiment_name=experiment_name,\n",
    "\t\tenemies=[enemy],\n",
    "\t\tplayermode=\"ai\",\n",
    "\t\tplayer_controller=player_controller(n_hidden1, n_hidden2),\n",
    "\t\tenemymode=\"ai\",\n",
    "\t\tlevel=2,\n",
    "\t\tspeed=\"fastest\",\n",
    "\t\tvisuals=True\n",
    "\t)\n",
    "\n",
    "\tf, _, _, _ = env.play(pcont=best_solutions_a)\n",
    "\n",
    "\tprint(f'Enemy {enemy}: Fitness = {f:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Fix Gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gain(solution, enemy, experiment_name, n_hidden_neurons_1, n_hidden_neurons_2, num_tests=5):\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(experiment_name, exist_ok=True)\n",
    "    \n",
    "    env = Environment(\n",
    "        experiment_name=experiment_name,\n",
    "\t\tenemies=[enemy],\n",
    "\t\tplayermode=\"ai\",\n",
    "\t\tplayer_controller=player_controller(n_hidden_neurons_1, n_hidden_neurons_2),\n",
    "\t\tenemymode=\"ai\",\n",
    "\t\tlevel=2,\n",
    "\t\tspeed=\"fastest\",\n",
    "\t\tvisuals=False\n",
    "    )\n",
    "    \n",
    "    gains = []\n",
    "    for _ in range(num_tests):\n",
    "        f, p_e, e_e, _ = env.play(pcont=solution)\n",
    "        gain = p_e - e_e\n",
    "        print(f'Gain: {gain:.4f}')\n",
    "        gains.append(gain)\n",
    "    return gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data storage for gains\n",
    "gains_data = {\n",
    "\t'Algorithm': [],\n",
    "\t'Enemy': [],\n",
    "\t'Run': [],\n",
    "\t'Gain': []\n",
    "}\n",
    "\n",
    "# Collect Gains for Best Solutions\n",
    "for index, row in best_solutions_df.iterrows():\n",
    "\talgo = row['Algorithm']\n",
    "\tenemy = row['Enemy']\n",
    "\trun = row['Run']\n",
    "\tsolution = row['Best Solution']\n",
    "\t\n",
    "\tn_hidden_neurons_1 = 10\n",
    "\tn_hidden_neurons_2 = 5\n",
    "\n",
    "\tn_vars = (\n",
    "\t\t(env.get_num_sensors() + 1) * n_hidden_neurons_1 +  # Weights and biases from input -> hidden layer 1\n",
    "\t\t(n_hidden_neurons_1 + 1) * n_hidden_neurons_2 +  # Weights and biases from hidden layer 1 -> hidden layer 2\n",
    "\t\t(n_hidden_neurons_2 + 1) * 5  # Weights and biases from hidden layer 2 -> output layer (5 actions)\n",
    "\t)\n",
    "\t\n",
    "\t# Define a unique experiment name for gain calculation\n",
    "\texperiment_name_gain = f'gains_{algo}_enemy_{enemy}_run_{run}'\n",
    "\t\n",
    "\t# Calculate gains\n",
    "\tgains = calculate_gain(solution, enemy, experiment_name_gain, n_hidden_neurons_1, n_hidden_neurons_2, num_tests=5)\n",
    "\t\n",
    "\tfor gain in gains:\n",
    "\t\tgains_data['Algorithm'].append(algo)\n",
    "\t\tgains_data['Enemy'].append(enemy)\n",
    "\t\tgains_data['Run'].append(run)\n",
    "\t\tgains_data['Gain'].append(gain)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_gains = pd.DataFrame(gains_data)\n",
    "\n",
    "# Display the first few rows of the gains data\n",
    "df_gains.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for enemy in enemies:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(data=df_gains[(df_gains['Enemy'] == enemy)], x='Algorithm', y='Gain')\n",
    "    plt.title(f'Enemy {enemy}: Individual Gain Comparison Between Algorithms')\n",
    "    plt.xlabel('Algorithm')\n",
    "    plt.ylabel('Gain (Player Energy - Enemy Energy)')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
