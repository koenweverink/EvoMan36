{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from evoman.environment import Environment\n",
    "from controller1 import player_controller\n",
    "from evoman.controller import Controller\n",
    "from multiprocessing import Pool\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm_a(env, npopulation=200, gens=30, mutation_rate=0.05, dom_u=1, dom_l=-1):\n",
    "\t\"\"\"\n",
    "\tRuns Genetic Algorithm A with the provided environment and parameters.\n",
    "\n",
    "\tParameters:\n",
    "\t- env: Evoman Environment instance.\n",
    "\t- npopulation: Population size.\n",
    "\t- gens: Number of generations.\n",
    "\t- mutation_rate: Mutation rate.\n",
    "\t- dom_u: Upper bound for gene values.\n",
    "\t- dom_l: Lower bound for gene values.\n",
    "\t- elitism_count: Number of elites to preserve.\n",
    "\n",
    "\tReturns:\n",
    "\t- history_mean: List of mean fitness per generation.\n",
    "\t- history_max: List of max fitness per generation.\n",
    "\t- best_solution: Best solution found.\n",
    "\t\"\"\"\n",
    "\tn_hidden_neurons_1 = 10\n",
    "\tn_hidden_neurons_2 = 5\n",
    "\n",
    "\tn_vars = (\n",
    "\t\t(env.get_num_sensors() + 1) * n_hidden_neurons_1 +  # Weights and biases from input -> hidden layer 1\n",
    "\t\t(n_hidden_neurons_1 + 1) * n_hidden_neurons_2 +  # Weights and biases from hidden layer 1 -> hidden layer 2\n",
    "\t\t(n_hidden_neurons_2 + 1) * 5  # Weights and biases from hidden layer 2 -> output layer (5 actions)\n",
    "\t)\n",
    "\t# Run the simulation and return the fitness\n",
    "\tdef simulate(x):\n",
    "\t\tf, _, _, _ = env.play(pcont=x)\n",
    "\t\treturn f\n",
    "\n",
    "\t# Evaluate the current population\n",
    "\tdef evaluate(population):\n",
    "\t\treturn np.array([simulate(individual) for individual in population])\n",
    "\n",
    "\t# Tournament Selection\n",
    "\tdef tournament_selection(population, fitness, k=5):\n",
    "\t\tselected = []\n",
    "\t\tfor _ in range(len(population)):\n",
    "\t\t\tcontenders = np.random.choice(len(population), k, replace=False)\n",
    "\t\t\twinner = contenders[np.argmax(fitness[contenders])]\n",
    "\t\t\tselected.append(population[winner])\n",
    "\t\treturn np.array(selected)\n",
    "\n",
    "\t# Uniform Crossover\n",
    "\tdef crossover(parent1, parent2):\n",
    "\t\tmask = np.random.rand(n_vars) < 0.5\n",
    "\t\tchild1 = np.where(mask, parent1, parent2)\n",
    "\t\tchild2 = np.where(mask, parent2, parent1)\n",
    "\t\treturn child1, child2\n",
    "\n",
    "\t# Gaussian Mutation\n",
    "\tdef mutate(child):\n",
    "\t\tfor i in range(n_vars):\n",
    "\t\t\tif np.random.rand() < mutation_rate:\n",
    "\t\t\t\tchild[i] += np.random.normal(0, 0.1)\n",
    "\t\t\t\tchild[i] = np.clip(child[i], dom_l, dom_u)\n",
    "\t\treturn child\n",
    "\n",
    "\t# Initialize population\n",
    "\tpopulation = np.random.uniform(dom_l, dom_u, (npopulation, n_vars))\n",
    "\tfitness = evaluate(population)\n",
    "\n",
    "\t# Record fitness over generations\n",
    "\thistory_mean = []\n",
    "\thistory_max = []\n",
    "\n",
    "\t# Genetic Algorithm Loop\n",
    "\tfor generation in range(1, gens + 1):\n",
    "\t\t# Selection\n",
    "\t\tselected = tournament_selection(population, fitness)\n",
    "\n",
    "\t\t# Crossover\n",
    "\t\toffspring = []\n",
    "\t\tfor i in range(0, npopulation, 2):\n",
    "\t\t\tparent1, parent2 = selected[i], selected[i+1]\n",
    "\t\t\tchild1, child2 = crossover(parent1, parent2)\n",
    "\t\t\toffspring.extend([child1, child2])\n",
    "\t\toffspring = np.array(offspring)[:npopulation]\n",
    "\n",
    "\t\t# Mutation\n",
    "\t\toffspring = np.array([mutate(child) for child in offspring])\n",
    "\n",
    "\t\t# Evaluation\n",
    "\t\toffspring_fitness = evaluate(offspring)\n",
    "\n",
    "\t\t# Replacement: Elitism (keep the best individual) (Could maybe change this)\n",
    "\t\tbest_idx = np.argmax(fitness)\n",
    "\t\tworst_idx = np.argmin(offspring_fitness)\n",
    "\t\tif fitness[best_idx] > offspring_fitness[worst_idx]:\n",
    "\t\t\toffspring[worst_idx] = population[best_idx]\n",
    "\t\t\toffspring_fitness[worst_idx] = fitness[best_idx]\n",
    "\t\t\n",
    "\t\tpopulation, fitness = offspring, offspring_fitness\n",
    "\n",
    "\t\t# Record statistics\n",
    "\t\thistory_mean.append(np.mean(fitness))\n",
    "\t\thistory_max.append(np.max(fitness))\n",
    "\n",
    "\t\t# Logging\n",
    "\t\tprint(f'Generation {generation}: Best Fitness = {history_max[-1]:.4f}, Mean Fitness = {history_mean[-1]:.4f}')\n",
    "\n",
    "\t# Get best solution\n",
    "\tbest_idx = np.argmax(fitness)\n",
    "\tbest_solution = population[best_idx]\n",
    "\n",
    "\tnp.savetxt(('best_solution_a.txt'), best_solution)\n",
    "\n",
    "\treturn history_mean, history_max, best_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm_b(env, npopulation=200, gens=30, mutation_rate=0.05, dom_u=1, dom_l=-1, elitism_count=2, share_alpha=0.1, share_sigma=0.2):\n",
    "\t\"\"\"\n",
    "\tRuns Genetic Algorithm B (GA with Fitness Sharing for diversity maintenance).\n",
    "\n",
    "\tParameters:\n",
    "\t- env: Evoman Environment instance.\n",
    "\t- npopulation: Population size.\n",
    "\t- gens: Number of generations.\n",
    "\t- mutation_rate: Mutation rate.\n",
    "\t- dom_u: Upper bound for gene values.\n",
    "\t- dom_l: Lower bound for gene values.\n",
    "\t- elitism_count: Number of elites to preserve.\n",
    "\t- share_alpha: Sharing coefficient.\n",
    "\t- share_sigma: Sharing radius.\n",
    "\n",
    "\tReturns:\n",
    "\t- history_mean: List of mean fitness per generation.\n",
    "\t- history_max: List of max fitness per generation.\n",
    "\t- best_solution: Best solution found.\n",
    "\t\"\"\"\n",
    "\n",
    "\tn_hidden_neurons_1 = 10\n",
    "\tn_hidden_neurons_2 = 5\n",
    "\n",
    "\tn_vars = (\n",
    "\t\t(env.get_num_sensors() + 1) * n_hidden_neurons_1 +  # Weights and biases from input -> hidden layer 1\n",
    "\t\t(n_hidden_neurons_1 + 1) * n_hidden_neurons_2 +  # Weights and biases from hidden layer 1 -> hidden layer 2\n",
    "\t\t(n_hidden_neurons_2 + 1) * 5  # Weights and biases from hidden layer 2 -> output layer (5 actions)\n",
    "\t)\n",
    "\n",
    "\t# Run the simulation and return the fitness\n",
    "\tdef simulate(x):\n",
    "\t\tf, _, _, _ = env.play(pcont=x)\n",
    "\t\treturn f\n",
    "\n",
    "\t# Evaluate the current population\n",
    "\tdef evaluate(population):\n",
    "\t\treturn np.array([simulate(individual) for individual in population])\n",
    "\n",
    "\t# Tournament Selection\n",
    "\tdef tournament_selection(population, fitness, k=5):\n",
    "\t\tselected = []\n",
    "\t\tfor _ in range(len(population)):\n",
    "\t\t\tcontenders = np.random.choice(len(population), k, replace=False)\n",
    "\t\t\twinner = contenders[np.argmax(fitness[contenders])]\n",
    "\t\t\tselected.append(population[winner])\n",
    "\t\treturn np.array(selected)\n",
    "\n",
    "\t# Two-Point Crossover\n",
    "\tdef two_point_crossover(parent1, parent2):\n",
    "\t\tpoint1 = np.random.randint(0, n_vars)\n",
    "\t\tpoint2 = np.random.randint(point1, n_vars)\n",
    "\t\tchild1 = np.concatenate([parent1[:point1], parent2[point1:point2], parent1[point2:]])\n",
    "\t\tchild2 = np.concatenate([parent2[:point1], parent1[point1:point2], parent2[point2:]])\n",
    "\t\treturn child1, child2\n",
    "\n",
    "\t# Gaussian Mutation\n",
    "\tdef mutate(child):\n",
    "\t\tfor i in range(n_vars):\n",
    "\t\t\tif np.random.rand() < mutation_rate:\n",
    "\t\t\t\tchild[i] += np.random.normal(0, 0.1)\n",
    "\t\t\t\tchild[i] = np.clip(child[i], dom_l, dom_u)\n",
    "\t\treturn child\n",
    "\n",
    "\t# Fitness Sharing\n",
    "\tdef fitness_sharing(population, fitness, alpha, sigma):\n",
    "\t\t\"\"\"\n",
    "\t\tAdjusts fitness based on similarity using fitness sharing.\n",
    "\n",
    "\t\tParameters:\n",
    "\t\t- population: Current population.\n",
    "\t\t- fitness: Original fitness values.\n",
    "\t\t- alpha: Sharing coefficient.\n",
    "\t\t- sigma: Sharing radius.\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t- shared_fitness: Adjusted fitness values.\n",
    "\t\t\"\"\"\n",
    "\t\tshared_fitness = np.copy(fitness)\n",
    "\t\tnpop = population.shape[0]\n",
    "\t\tfor i in range(npop):\n",
    "\t\t\tfor j in range(npop):\n",
    "\t\t\t\tif i != j:\n",
    "\t\t\t\t\tdistance = np.linalg.norm(population[i] - population[j])\n",
    "\t\t\t\t\tif distance < sigma:\n",
    "\t\t\t\t\t\tshared_fitness[i] -= alpha * (1 - distance / sigma)\n",
    "\t\t# Ensure that fitness doesn't become negative\n",
    "\t\tshared_fitness = np.maximum(shared_fitness, 0)\n",
    "\t\treturn shared_fitness\n",
    "\n",
    "\t# Initialize population\n",
    "\tpopulation = np.random.uniform(dom_l, dom_u, (npopulation, n_vars))\n",
    "\tfitness = evaluate(population)\n",
    "\n",
    "\t# Apply Fitness Sharing\n",
    "\tfitness = fitness_sharing(population, fitness, share_alpha, share_sigma)\n",
    "\n",
    "\t# Record fitness over generations\n",
    "\thistory_mean = []\n",
    "\thistory_max = []\n",
    "\n",
    "\t# Genetic Algorithm Loop\n",
    "\tfor generation in range(1, gens + 1):\n",
    "\t\t# Selection\n",
    "\t\tselected = tournament_selection(population, fitness)\n",
    "\n",
    "\t\t# Crossover\n",
    "\t\toffspring = []\n",
    "\t\tfor i in range(0, npopulation, 2):\n",
    "\t\t\tparent1, parent2 = selected[i], selected[i+1]\n",
    "\t\t\tchild1, child2 = two_point_crossover(parent1, parent2)\n",
    "\t\t\toffspring.extend([child1, child2])\n",
    "\t\toffspring = np.array(offspring)[:npopulation]\n",
    "\n",
    "\t\t# Mutation\n",
    "\t\toffspring = np.array([mutate(child) for child in offspring])\n",
    "\n",
    "\t\t# Evaluation\n",
    "\t\toffspring_fitness = evaluate(offspring)\n",
    "\n",
    "\t\t# Apply Fitness Sharing\n",
    "\t\toffspring_fitness = fitness_sharing(offspring, offspring_fitness, share_alpha, share_sigma)\n",
    "\n",
    "\t\t# Replacement: Elitism (keep the best individual) (Could maybe change this)\n",
    "\t\tbest_idx = np.argmax(fitness)\n",
    "\t\tworst_idx = np.argmin(offspring_fitness)\n",
    "\t\tif fitness[best_idx] > offspring_fitness[worst_idx]:\n",
    "\t\t\toffspring[worst_idx] = population[best_idx]\n",
    "\t\t\toffspring_fitness[worst_idx] = fitness[best_idx]\n",
    "\n",
    "\t\tpopulation, fitness = offspring, offspring_fitness\n",
    "\n",
    "\t\t# Record statistics\n",
    "\t\thistory_mean.append(np.mean(fitness))\n",
    "\t\thistory_max.append(np.max(fitness))\n",
    "\n",
    "\t\t# Logging\n",
    "\t\tprint(f'Generation {generation}: Best Fitness = {history_max[-1]:.4f}, Mean Fitness = {history_mean[-1]:.4f}')\n",
    "\n",
    "\t# Get best solution\n",
    "\tbest_idx = np.argmax(fitness)\n",
    "\tbest_solution = population[best_idx]\n",
    "\n",
    "\tnp.savetxt(('best_solution_b.txt'), best_solution)\n",
    "\n",
    "\treturn history_mean, history_max, best_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Parameters\n",
    "enemy = 6\n",
    "num_runs = 2  \t\t\t# Change to 10 for full experiment\n",
    "npopulation = 200\n",
    "gens = 10 \t\t\t\t# Change to 30 for full experiment\n",
    "mutation_rate = 0.05\n",
    "dom_u, dom_l = 1, -1\n",
    "elitism_count_a = 1  \t# For Algorithm A\n",
    "elitism_count_b = 2  \t# For Algorithm B\n",
    "n_hidden1 = 10\n",
    "n_hidden2 = 5\n",
    "\n",
    "\n",
    "# Initialize data storage\n",
    "results = {\n",
    "    'Algorithm': [],\n",
    "    'Enemy': [],\n",
    "    'Run': [],\n",
    "    'Generation': [],\n",
    "    'Mean Fitness': [],\n",
    "    'Max Fitness': [],\n",
    "    'Best Solution': []\n",
    "}\n",
    "\n",
    "best_solutions = {\n",
    "    'Algorithm': [],\n",
    "    'Enemy': [],\n",
    "    'Run': [],\n",
    "    'Best Solution': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_neurons_1 = 10\n",
    "n_hidden_neurons_2 = 5\n",
    "\n",
    "for run in range(1, num_runs + 1):\n",
    "\tprint(f\"Run {run}/{num_runs}\")\n",
    "\t\n",
    "\t# Define experiment names for Algorithm A and B\n",
    "\texperiment_name_a = f'optimization_test_a_run_{run}'\n",
    "\texperiment_name_b = f'optimization_test_b_run_{run}'\n",
    "\t\n",
    "\t# Create directories for Algorithm A and B\n",
    "\tos.makedirs(experiment_name_a, exist_ok=True)\n",
    "\tos.makedirs(experiment_name_b, exist_ok=True)\n",
    "\t\n",
    "\t# Initialize Environment for Algorithm A\n",
    "\tenv_a = Environment(\n",
    "\t\texperiment_name=experiment_name_a,\n",
    "\t\tenemies=[enemy],\n",
    "\t\tplayermode=\"ai\",\n",
    "\t\tplayer_controller=player_controller(n_hidden_neurons_1, n_hidden_neurons_2),\n",
    "\t\tenemymode=\"ai\",\n",
    "\t\tlevel=2,\n",
    "\t\tspeed=\"fastest\",\n",
    "\t\tvisuals=False\n",
    "\t)\n",
    "\t\n",
    "\t# Run Algorithm A\n",
    "\tmean_a, max_a, best_a = run_algorithm_a(\n",
    "\t\tenv=env_a,\n",
    "\t\tnpopulation=npopulation,\n",
    "\t\tgens=gens,\n",
    "\t\tmutation_rate=mutation_rate,\n",
    "\t\tdom_u=dom_u,\n",
    "\t\tdom_l=dom_l\n",
    "\t)\n",
    "\t\n",
    "\t# Record data for Algorithm A\n",
    "\tfor gen in range(1, gens + 1):\n",
    "\t\tresults['Algorithm'].append('A')\n",
    "\t\tresults['Enemy'].append(enemy)\n",
    "\t\tresults['Run'].append(run)\n",
    "\t\tresults['Generation'].append(gen)\n",
    "\t\tresults['Mean Fitness'].append(mean_a[gen - 1])\n",
    "\t\tresults['Max Fitness'].append(max_a[gen - 1])\n",
    "\t\tresults['Best Solution'].append(best_a)\n",
    "\t\n",
    "\tbest_solutions['Algorithm'].append('A')\n",
    "\tbest_solutions['Enemy'].append(enemy)\n",
    "\tbest_solutions['Run'].append(run)\n",
    "\tbest_solutions['Best Solution'].append(best_a)\n",
    "\t\n",
    "\t\n",
    "\t# Initialize Environment for Algorithm B\n",
    "\tenv_b = Environment(\n",
    "\t\texperiment_name=experiment_name_b,\n",
    "\t\tenemies=[enemy],\n",
    "\t\tplayermode=\"ai\",\n",
    "\t\tplayer_controller=player_controller(n_hidden_neurons_1, n_hidden_neurons_2),\n",
    "\t\tenemymode=\"ai\",\n",
    "\t\tlevel=2,\n",
    "\t\tspeed=\"fastest\",\n",
    "\t\tvisuals=False\n",
    "\t)\n",
    "\t\n",
    "\t# Run Algorithm B\n",
    "\tmean_b, max_b, best_b = run_algorithm_b(\n",
    "\t\tenv=env_b,\n",
    "\t\tnpopulation=npopulation,\n",
    "\t\tgens=gens,\n",
    "\t\tmutation_rate=mutation_rate,\n",
    "\t\tdom_u=dom_u,\n",
    "\t\tdom_l=dom_l,\n",
    "\t\telitism_count=elitism_count_b\n",
    "\t)\n",
    "\t\n",
    "\t# Record data for Algorithm B\n",
    "\tfor gen in range(1, gens + 1):\n",
    "\t\tresults['Algorithm'].append('B')\n",
    "\t\tresults['Enemy'].append(enemy)\n",
    "\t\tresults['Run'].append(run)\n",
    "\t\tresults['Generation'].append(gen)\n",
    "\t\tresults['Mean Fitness'].append(mean_b[gen - 1])\n",
    "\t\tresults['Max Fitness'].append(max_b[gen - 1])\n",
    "\t\tresults['Best Solution'].append(best_b)\n",
    "\t\n",
    "\tbest_solutions['Algorithm'].append('B')\n",
    "\tbest_solutions['Enemy'].append(enemy)\n",
    "\tbest_solutions['Run'].append(run)\n",
    "\tbest_solutions['Best Solution'].append(best_b)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('results.csv', index=False)\n",
    "\n",
    "best_solutions_df = pd.DataFrame(best_solutions)\n",
    "best_solutions_df.to_csv('best_solutions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Algorithm, Enemy, Generation and compute mean and std\n",
    "grouped = results_df.groupby(['Algorithm', 'Enemy', 'Generation']).agg(\n",
    "    mean_fitness_mean=('Mean Fitness', 'mean'),\n",
    "    mean_fitness_std=('Mean Fitness', 'std'),\n",
    "    max_fitness_mean=('Max Fitness', 'mean'),\n",
    "    max_fitness_std=('Max Fitness', 'std')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the grouped data\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Subset data for the current enemy\n",
    "data_enemy = grouped[grouped['Enemy'] == enemy]\n",
    "\n",
    "# Plot Mean Fitness\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.lineplot(data=data_enemy, x='Generation', y='mean_fitness_mean', hue='Algorithm', marker='o')\n",
    "plt.fill_between(\n",
    "\tdata_enemy['Generation'],\n",
    "\tdata_enemy['mean_fitness_mean'] - data_enemy['mean_fitness_std'],\n",
    "\tdata_enemy['mean_fitness_mean'] + data_enemy['mean_fitness_std'],\n",
    "\talpha=0.2\n",
    ")\n",
    "plt.title(f'Enemy {enemy}: Average Mean Fitness Across Generations')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Mean Fitness')\n",
    "plt.legend(title='Algorithm')\n",
    "\n",
    "# Plot Max Fitness\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.lineplot(data=data_enemy, x='Generation', y='max_fitness_mean', hue='Algorithm', marker='o')\n",
    "plt.fill_between(\n",
    "\tdata_enemy['Generation'],\n",
    "\tdata_enemy['max_fitness_mean'] - data_enemy['max_fitness_std'],\n",
    "\tdata_enemy['max_fitness_mean'] + data_enemy['max_fitness_std'],\n",
    "\talpha=0.2\n",
    ")\n",
    "plt.title(f'Enemy {enemy}: Average Max Fitness Across Generations')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Max Fitness')\n",
    "plt.legend(title='Algorithm')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Run the best solution on 2 other enemies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enemies = [1, 6, 8]\n",
    "\n",
    "experiment_name = 'test_other_enemies'\n",
    "os.makedirs(experiment_name, exist_ok=True)\n",
    "\n",
    "# Load best solutions\n",
    "best_solutions_a = np.loadtxt('best_solution_b.txt')\n",
    "\n",
    "n_hidden1 = 10\n",
    "n_hidden2 = 5\n",
    "\n",
    "for enemy in enemies:\n",
    "\tenv = Environment(\n",
    "\t\texperiment_name=experiment_name,\n",
    "\t\tenemies=[enemy],\n",
    "\t\tplayermode=\"ai\",\n",
    "\t\tplayer_controller=player_controller(n_hidden1, n_hidden2),\n",
    "\t\tenemymode=\"ai\",\n",
    "\t\tlevel=2,\n",
    "\t\tspeed=\"fastest\",\n",
    "\t\tvisuals=True\n",
    "\t)\n",
    "\n",
    "\tf, _, _, _ = env.play(pcont=best_solutions_a)\n",
    "\n",
    "\tprint(f'Enemy {enemy}: Fitness = {f:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Fix Gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gain(solution, enemy, experiment_name, n_hidden_neurons_1, n_hidden_neurons_2, num_tests=5):\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(experiment_name, exist_ok=True)\n",
    "    \n",
    "    env = Environment(\n",
    "        experiment_name=experiment_name,\n",
    "\t\tenemies=[enemy],\n",
    "\t\tplayermode=\"ai\",\n",
    "\t\tplayer_controller=player_controller(n_hidden_neurons_1, n_hidden_neurons_2),\n",
    "\t\tenemymode=\"ai\",\n",
    "\t\tlevel=2,\n",
    "\t\tspeed=\"fastest\",\n",
    "\t\tvisuals=False\n",
    "    )\n",
    "    \n",
    "    gains = []\n",
    "    for _ in range(num_tests):\n",
    "        f, p_e, e_e, _ = env.play(pcont=solution)\n",
    "        gain = p_e - e_e\n",
    "        print(f'Gain: {gain:.4f}')\n",
    "        gains.append(gain)\n",
    "    return gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data storage for gains\n",
    "gains_data = {\n",
    "\t'Algorithm': [],\n",
    "\t'Enemy': [],\n",
    "\t'Run': [],\n",
    "\t'Gain': []\n",
    "}\n",
    "\n",
    "# Collect Gains for Best Solutions\n",
    "for index, row in best_solutions_df.iterrows():\n",
    "\talgo = row['Algorithm']\n",
    "\tenemy = row['Enemy']\n",
    "\trun = row['Run']\n",
    "\tsolution = row['Best Solution']\n",
    "\t\n",
    "\tn_hidden_neurons_1 = 10\n",
    "\tn_hidden_neurons_2 = 5\n",
    "\n",
    "\tn_vars = (\n",
    "\t\t(env.get_num_sensors() + 1) * n_hidden_neurons_1 +  # Weights and biases from input -> hidden layer 1\n",
    "\t\t(n_hidden_neurons_1 + 1) * n_hidden_neurons_2 +  # Weights and biases from hidden layer 1 -> hidden layer 2\n",
    "\t\t(n_hidden_neurons_2 + 1) * 5  # Weights and biases from hidden layer 2 -> output layer (5 actions)\n",
    "\t)\n",
    "\t\n",
    "\t# Define a unique experiment name for gain calculation\n",
    "\texperiment_name_gain = f'gains_{algo}_enemy_{enemy}_run_{run}'\n",
    "\t\n",
    "\t# Calculate gains\n",
    "\tgains = calculate_gain(solution, enemy, experiment_name_gain, n_hidden_neurons_1, n_hidden_neurons_2, num_tests=5)\n",
    "\t\n",
    "\tfor gain in gains:\n",
    "\t\tgains_data['Algorithm'].append(algo)\n",
    "\t\tgains_data['Enemy'].append(enemy)\n",
    "\t\tgains_data['Run'].append(run)\n",
    "\t\tgains_data['Gain'].append(gain)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_gains = pd.DataFrame(gains_data)\n",
    "\n",
    "# Display the first few rows of the gains data\n",
    "df_gains.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for enemy in enemies:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(data=df_gains[(df_gains['Enemy'] == enemy)], x='Algorithm', y='Gain')\n",
    "    plt.title(f'Enemy {enemy}: Individual Gain Comparison Between Algorithms')\n",
    "    plt.xlabel('Algorithm')\n",
    "    plt.ylabel('Gain (Player Energy - Enemy Energy)')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
